<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"> 
    <head>
        <title>Ting Dang | About</title>
        
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
        <meta name="author" content="Ting Dang">
        <meta name="description" content="University of Melbourne, Australia">
        <meta name="og:title" content="Ting Dang">
        
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
        <link href="https://use.fontawesome.com/releases/v5.0.6/css/all.css" rel="stylesheet">
        <link href="style.css" rel="stylesheet">
        <link rel="shortcut icon" href="mel.jpg" type="image/x-icon">
        <style>
            .profile-section { margin-bottom: 30px; }
            .profile-image { max-width: 200px; margin-bottom: 15px; }
            .cv-button { margin-top: 10px; }
            .section-title { border-bottom: 2px solid #336699; padding-bottom: 10px; margin-bottom: 20px; }
            .news-item { margin-bottom: 15px; }
            
            /* Full-width banner styling */
            .lab-banner-container {
                width: 100%;
                margin-left: 0;
                margin-right: 0;
                margin-top: 50px;
                padding: 0;
                position: relative;
            }
            
            .lab-banner {
                position: relative;
                height: 600px;
                width: 100%;
                overflow: hidden;
                color: white;
                margin: 0;
                padding: 0;
            }
            
            .lab-banner::before {
                content: "";
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                background: linear-gradient(rgba(0,0,0,0.5), rgba(0,0,0,0.7));
                z-index: 1;
            }
            
            .lab-banner .content {
                position: absolute;
                top: 50%;
                left: 50%;
                transform: translate(-50%, -50%);
                z-index: 2;
                text-align: center;
                width: 80%;
                max-width: 1000px;
            }
            
            .lab-banner h2 {
                color: white;
                margin-bottom: 30px;
                font-weight: bold;
                font-size: 56px;
                text-shadow: 2px 2px 4px rgba(0,0,0,0.7);
            }
            
            .lab-banner .lead {
                color: white;
                font-size: 24px;
                margin: 0 auto;
                text-shadow: 1px 1px 3px rgba(0,0,0,0.7);
                line-height: 1.6;
            }
            
            .lab-background {
                position: absolute;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                object-fit: cover;
                object-position: center;
                z-index: 0;
            }
            
            /* Full-width container styling - ADD TO style.css FOR ALL PAGES */
            .wide-container {
                width: 95%;
                max-width: 1800px;
                margin-left: auto;
                margin-right: auto;
                padding-left: 15px;
                padding-right: 15px;
            }
            
            /* Add space between banner and content */
            .content-section {
                margin-top: 40px;
            }

            @media (max-width: 767px) {
                .navbar-nav {
                    margin: 0;
                }
                .navbar-nav > li {
                    float: none;
                }
                .navbar-nav > li > a {
                    padding-top: 10px;
                    padding-bottom: 10px;
                }
                .navbar-collapse {
                    border-top: 1px solid #444;
                }
                .lab-banner {
                    height: 400px;
                }
                .lab-banner h2 {
                    font-size: 36px;
                }
                .lab-banner .lead {
                    font-size: 20px;
                }
                .wide-container {
                    width: 98%;
                    padding-left: 10px;
                    padding-right: 10px;
                }
            }

            @media (min-width: 768px) {
                .navbar-nav {
                    float: right;
                }
            }
        </style>
    </head>
    
    <body>
        <nav class="navbar navbar-inverse navbar-fixed-top">
            <div class="wide-container">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="index.html">Ting Dang</a>
                </div>
                <div id="navbar" class="collapse navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a href="index.html">About</a></li>
                        <li><a href="research_projects.html">Research Projects</a></li>
                        <li><a href="publications.html">Publications</a></li>
                        <li><a href="people.html">Team</a></li>
                        <li><a href="achievements.html">Achievements</a></li>
                        <li><a href="teaching_and_services.html">Teaching & Services</a></li>
                        <li><a href="hiring.html">Hiring</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        
        <!-- Full-width banner that spans the entire page -->
        <!-- <div class="lab-banner">
            <img src="lab_figure.png" alt="AudioWear Intelligence Lab Background" class="lab-background">
            <div class="content">
                <h2>AudioWear Intelligence Lab</h2>
                <p class="lead">Exploring the intersection of audio processing, wearable technology, and artificial intelligence for mobile health applications</p>
            </div>
        </div> -->
        
        <div class="wide-container content-section">            
            <div class="row profile-section">
                <div class="col-md-8">
                    <h2>Ting Dang</h2>
                    <h4>Senior Lecturer, The University of Melbourne</h4>
                    <h5>ting.dang@unimelb.edu.au <a href="mailto:ting.dang@unimelb.edu.au"><span class="glyphicon glyphicon-envelope"></span></a></h5>
                    <h5>
                        <a href="https://scholar.google.com.au/citations?view_op=list_works&hl=en&hl=en&user=Sb1Pj4sAAAAJ&sortby=pubdate">Google Scholar</a> | 
                        <a href="https://www.researchgate.net/profile/Ting-Dang">ResearchGate</a> | 
                        <a href="https://www.linkedin.com/in/ting-dang-9928b6145/">LinkedIn</a> | 
                        <a href="https://x.com/tingdang513">Twitter</a> |
                        <a href="https://findanexpert.unimelb.edu.au/profile/1065466-ting-dang">University Profile</a>
                    </h5>
                    <h6><strong>Mobile Health - Audio and Speech Processing</strong></h6>
                    <h6><strong>Deep Learning - Affective Computing - Time Series Modelling</strong></h6>
                    <a href="TingDangCV_public.pdf" class="btn btn-primary btn-xs cv-button"><i class="fa fa-file-pdf"></i> CV</a>
                </div>
                <div class="col-md-4 text-right">
                    <div style="padding-top: 30px;">
                        <img src="ting_large.jpg" alt="Ting Dang" class="img-responsive img-circle profile-image">
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">About Me</h3>
                    <p style="text-align:justify;">
                        I am a Senior Lecturer at the University of Melbourne. Previously, I served as a Senior Research Scientist at Nokia Bell Labs in the UK, a Senior Research Associate at the University of Cambridge, and a Research Associate at the University of New South Wales (UNSW), Australia, where I also earned my Ph.D. My research primarily focuses on human-centered AI and sensing for health delivery. Specifically, I develop AI models that leverage audio signals (such as speech and breathing) and physiological signals (like PPG and EEG) through mobile and wearable sensing to detect and monitor health conditions. I am serving as the Editor for IEEE Pervasive Computing and Elsevier Computer Speech and Language, an Area Chair for ICASSP and Senior PC for AAAI.  
                    </p>
                    <h4>Research Interests</h4>
                    <ul>
                        <li><strong>Machine learning in mobile health:</strong> Pioneering the development of machine learning algorithms tailored for diverse health applications, aimed at enhancing the reliability and effectiveness of ML in screening, diagnosis, and monitoring.</li>
                        <li><strong>Speech and Audio Processing:</strong> Investigating advanced signal processing and machine learning techniques for speech and related applications.</li>
                        <li><strong>Time Series Modelling:</strong> Enhancing representation learning for time series in real-world challenges.</li>
                        <li><strong>Trustworthy Deep Learning (DL):</strong> Improving the interpretability and generalization of DL models for more reliable health outcome predictions.</li>
                        <li><strong>Wearable Sensing:</strong> Examining novel sensing opportunities for health monitoring using new forms of resource-constrained IoT wearable devices.</li>
                    </ul>

                    <h4>Opportunities</h4>
                    <!-- <p>We are currently looking for PhD students to work on machine learning for health and wearable sensing. Scholarships are available for eligible candidates. We also welcome applications from China Scholarship Council (CSC) students. For more details, please refer to our <a href="hiring.html">Hiring</a> page.</p>
                    <p>We also welcome visiting scholars to join our team if the research background aligns with our focus.</p> -->
                    <p>We welcome applications from China Scholarship Council (CSC) students and visiting scholars to join our team if the research background aligns with our focus. </p>
                </div>
            </div>

            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">News</h3>
                    <div style="text-align: justify; font-size:14px">
                        <div class="news-item">
                            <p>2025/11: Joined <strong>Editorial Board</strong> of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5165369">IEEE Transactions on Affective Computing</a>.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/09: Two papers and two workshop papers accepted at NeurIPS 2025.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/09: One paper accepted by SenSys 2026, titled 'From Cheap to Chic: Enhancing Music Playback Quality of Budget Earphones via Hardware-Aware Learning'.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/09: One paper accepted by IEEE Transactions on Affective Computing, titled '<a href="https://ieeexplore.ieee.org/document/11185123">How many raters do we need? Analyses of uncertainty in estimating ambiguity-aware emotion labels</a>'.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/09: One paper accepted by ACM Transactions on Computing for Healthcare, titled 'Data-Efficient Psychiatric Disorder Detection via Self-supervised Learning on Frequency-enhanced Brain Networks'.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/08: Shortlisted as the Finalist for the <a href="https://wocinstemawards.org/index.php/2025/08/27/announcing-the-finalists-for-the-2025-women-of-colour-in-stem-awards/" target="_blank">Rising Star (Academics) STEM Women in Color Award 2025</a>.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/08: Two papers accepted at APSIPA ASC 2025</a></strong>.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/08: One paper accepted at ACII LBR Track titled '<a href="https://arxiv.org/abs/2507.08031">Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding</a>'.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/07: Senior PC of AAAI 2026.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/07: Two papers accepted at UbiComp/ISWC 2025 workshops. 
                                <!-- titled 'Listening to the Mind: Earable Acoustic Sensing of Cognitive Load' and 'From Patient Burdens to User Agency: Designing for Real-Time Protection Support in Online Health Consultations'. -->
                            </p>
                        </div>
                        <div class="news-item">
                            <p>2025/06: Call for papers: <a href="https://sites.google.com/view/espresso2025">ESPRESSO: Special Session on Scalable and Efficient Signal Processing for Multimodal AI Systems</a> at APSIPA ASC 2025.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/05: Two papers accepted at INTERSPEECH 2025.
                        </div>
                        <div class="news-item">
                            <p>2025/04: Joined the <strong>Editorial Board</strong> of <a href="https://www.sciencedirect.com/journal/computer-speech-and-language">Computer Speech and Language</a>.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/04: One paper titled 'Speech Emotion Recognition Via CNN Transforemr and Multidimensional Attention Mechanism' is accepted by Speech Communication.</p>
                        </div>
                        <div class="news-item">
                            <p>2025/04: Call for papers: <a href="https://www.mdpi.com/journal/sensors/special_issues/J7059T5Z6I">Special Issue on State of the Art in Wearable Sensors for Health Monitoring</a> @ Sensors</p>
                        </div>
                        <div class="news-item">
                            <p>2025/03: Two US patents are granted.</p>
                        </div>
                        <!-- News items -->
                        <div class="news-item">
                            <p>2025/02: One paper titled '<a href="https://dl.acm.org/doi/10.1145/3723049">SQUIREDL: Sparse Sequence-to-Sequence Uncertainty Estimation in Evidential Deep Learning</a>' is accepted by ACM Transactions on Computing for Healthcare.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/12: Two papers are accepted by IEEE ICASSP 2025.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/12: One US patent titled '<a href="https://www.freepatentsonline.com/y2024/0412719.html">Cancellation of Ultrasonic Signals</a>' is granted.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/11: One paper titled '<a href="https://ieeexplore.ieee.org/document/10859301">Multimodal Large Language Models in Human-centered Health: Practical Insights</a>' is accepted by IEEE Pervasive Computing.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/10: Served as the Area Chair for ICASSP 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/09:One paper titled '<a href="https://openreview.net/pdf?id=XIcBCBe6C3">TinyTTA: Efficient Test-time Adaptation via Early-exit Ensembles on Edge Devices</a>' is accepted by NeurIPS 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/09: One paper titled '<a href="https://dl.acm.org/doi/10.1145/3636534.3698123">Efficient and Personalized Mobile Health Event Prediction via Small Language Models</a>' is accepted by MobiCom Workshop EIFCom 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/08: Call for Papers: <a href="https://sites.google.com/view/spandldeteriorate">Workshop on Multi-Biological Sensing Data for Speech and Language Deterioration Prediction</a> ACM MM Asia.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/07: One paper titled '<a href="https://dl.acm.org/doi/abs/10.1145/3627673.3679732">StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast</a>' is accepted by CIKM 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/07: One paper titled '<a href="https://www.researchgate.net/publication/384271111_Emotion_Recognition_Systems_Must_Embrace_Ambiguity">Emotion Recognition Systems Must Embrace Ambiguity</a>' is accepted by ACII Satellite Workshop EASE 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/07: One paper titled '<a href="https://dl.acm.org/doi/abs/10.1145/3675094.3678494">Exploring Large-Scale Language Models to Evaluate EEG-Based Multimodal Data for Mental Health</a>' is accepted by UbiComp Workshop WellComp 2024.</p>
                        </div>
                        <!-- <div class="news-item">
                            <p>2024/07: Served as the PC for the <a href="https://ease.ewi.tudelft.nl/#about">EASE Satellite Workshop</a> at ACII 2024.</p>
                        </div> -->
                        <div class="news-item">
                            <p>2024/07: Invited talk at University of New South Wales and University of Sydney.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/06: One paper titled '<a href="https://www.arxiv.org/abs/2407.21344">Dual-Constrained Dynamical Neural ODEs for Ambiguity-aware Continuous Emotion Prediction</a>' is accepted by Interspeech 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/05: Joined the <strong>Editorial Board</strong> of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7756">IEEE Pervasive Computing</a>.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/04: Co-organizing <a href="https://wellcomp2024.github.io/index.html">WellComp workshop</a> at UbiComp 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/03: Co-charing <a href="https://mobilehci.acm.org/2024/callforindustrialperspectives.php">industry perspectives</a> at MobileHCI 2024.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/03: One paper titled <a href="https://www.sciencedirect.com/science/article/pii/S1574119224000397">"An evaluation of heart rate monitoring with in-ear microphones under motion"</a> is accepted by Pervasive and Mobile Computing.</p>
                        </div>
                        <div class="news-item">
                            <p>2024/01: One paper titled <a href="https://ieeexplore.ieee.org/document/10423104">"Uncertainty-aware Health Diagnostics via Class-balanced Evidential Deep Learning"</a> is accepted by IEEE Journal of Biomedical and Health Informatics (J-BHI).</p>
                        </div>
                        <!-- <div class="news-item">
                            <p>2023/12: One paper is accepted by HotMobile 2024!</p>
                        </div> -->
                        <!-- <div class="news-item">
                            <p>2023/12: Two papers accepted by ICASSP 2024!</p>
                        </div> -->
                        <div class="news-item">
                            <p>2023/10: One review paper titled <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.230806">"Human-centered AI for mobile health sensing: challenges and opportunities"</a> is accepted by Royal Society Open Science!</p>
                        </div>
                        <!-- <div class="news-item">
                            <p>2023/10: Two papers are accepted by IMWUT!</p>
                        </div> -->
                        <div class="news-item">
                            <p>2023/09: <a href="https://ieeexplore.ieee.org/abstract/document/10388210">Best paper award</a> from ACII 2023!</p>
                        </div>
                        <!-- <div class="news-item">
                            <p>2023/08: One paper is accepted by Speech Communication!</p>
                        </div> -->
                        <!-- <div class="news-item">
                            <p>2023/07: We will be giving a tutorial on <a href="https://acii-conf.net/2023/program/tutorials/introduction-to-eye-and-audio-behaviour-computing-for-affect-analysis-in-wearable-contexts/">"Multi-model wearable eye and audio for affect analysis"</a> at ACII in MIT media lab this Sep and at ICMI in Paris this Oct!</p>
                        </div> -->
                        <!-- <div class="news-item">
                            <p>2023/06: Our paper has been recognized as <a href="https://ieeexplore.ieee.org/abstract/document/10095778">Top 3% at ICASSP 2023</a>!</p>
                        </div> -->
                        <div class="news-item">
                            <p>2023: Papers accepted by INTERSPEECH, ICASSP, ACII, KDD, IMWUT, JMIR, Speech Communication, etc!</p>
                        </div>
                        <!-- <div class="news-item">
                            <p>2023/04: Co-organizing <strong>WellComp Workshop 2023</strong> in conjunction with UbiComp!</p>
                        </div>
                        <div class="news-item">
                            <p>2023/03: Social media co-chair for INTERSPEECH 2026!</p>
                        </div> -->
                        <!-- <div class="news-item">
                            <p>2022/08: Coverage for our recent paper at JMIR by the University of Cambridge Department of Computer Science and Technology!</p>
                        </div> -->
                        <!-- <div class="news-item">
                            <p>2022: Papers accepted by JMIR, ICASSP, INTERSPEECH, TSRML2022 in NeurIPS, HotMobile, PerCom, etc!</p>
                        </div>
                        <div class="news-item">
                            <p>2021: Papers accepted by NeurIPS, NPJ digital medicine, Frontiers in Computer Science, INTERSPEECH, etc!</p>
                        </div> -->
                        <!-- Add more news items as needed -->
                    </div>
                </div>
            </div>

            <!-- <div class="row">
                <div class="col-md-6">
                    <h3 class="section-title">Experience</h3>
                    <ul class="list-unstyled">
                        <li><strong>Senior Lecturer, 2024-Present</strong><br>University of Melbourne, Australia</li>
                        <li><strong>Senior Research Scientist, 2023-2024</strong><br>Nokia Bell Labs, UK</li>
                        <li><strong>Senior Research Associate, 2021-2023</strong><br>University of Cambridge, UK</li>
                        <li><strong>Research Associate, 2018-2020</strong><br>University of New South Wales, Australia</li>
                    </ul>
                </div>

                <div class="col-md-6">
                    <h3 class="section-title">Education</h3>
                    <ul class="list-unstyled education-list">
                        <li>
                            <div class="degree"><strong>PhD, 2014-2018</strong></div>
                            <div class="institution">University of New South Wales, Australia</div>
                        </li>
                        <li>
                            <div class="degree"><strong>MEng, 2012-2015</strong></div>
                            <div class="institution">Northwestern Polytechnical University, China</div>
                        </li>
                        <li>
                            <div class="degree"><strong>BEng, 2008-2012</strong></div>
                            <div class="institution">Northwestern Polytechnical University, China</div>
                        </li>
                    </ul>
                </div>
            </div> -->

            <div class="footer discrete">
                <div class="wide-container">
                    <p>&copy; Ting Dang 2024</p>
                </div>
            </div>
        </div>

        <!-- Include your scripts here -->
        <script src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
        <script>
            $(document).ready(function() {
                // Close the navbar when a menu item is clicked
                $('.navbar-nav>li>a').on('click', function(){
                    $('.navbar-collapse').collapse('hide');
                });
            });
        </script>
    </body>
</html>